; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 5
; RUN: llc -march=v810 -stop-after=irtranslator -global-isel -verify-machineinstrs %s -o -| FileCheck %s

; Basic variadic method just to confirm we're lowering the intrinsics at all
define i32 @sum(i32 %count, ...) {
  ; CHECK-LABEL: name: sum
  ; CHECK: bb.1.entry:
  ; CHECK-NEXT:   successors: %bb.3(0x30000000), %bb.2(0x50000000)
  ; CHECK-NEXT:   liveins: $r6
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(s32) = COPY $r6
  ; CHECK-NEXT:   [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
  ; CHECK-NEXT:   [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 -1
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.args
  ; CHECK-NEXT:   G_VASTART [[FRAME_INDEX]](p0) :: (store (s32) into %ir.args)
  ; CHECK-NEXT:   [[ICMP:%[0-9]+]]:_(s1) = G_ICMP intpred(eq), [[COPY]](s32), [[C]]
  ; CHECK-NEXT:   G_BRCOND [[ICMP]](s1), %bb.3
  ; CHECK-NEXT:   G_BR %bb.2
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2.for.body.preheader:
  ; CHECK-NEXT:   successors: %bb.4(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   G_BR %bb.4
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.3.for.cond.cleanup:
  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:_(s32) = G_PHI [[C]](s32), %bb.1, %7(s32), %bb.4
  ; CHECK-NEXT:   $r10 = COPY [[PHI]](s32)
  ; CHECK-NEXT:   RET implicit $r10
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.4.for.body:
  ; CHECK-NEXT:   successors: %bb.3(0x04000000), %bb.4(0x7c000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PHI1:%[0-9]+]]:_(s32) = G_PHI [[COPY]](s32), %bb.2, %9(s32), %bb.4
  ; CHECK-NEXT:   [[PHI2:%[0-9]+]]:_(s32) = G_PHI %7(s32), %bb.4, [[C]](s32), %bb.2
  ; CHECK-NEXT:   [[VAARG:%[0-9]+]]:_(s32) = G_VAARG [[FRAME_INDEX]](p0), 4
  ; CHECK-NEXT:   [[ADD:%[0-9]+]]:_(s32) = G_ADD [[VAARG]], [[PHI2]]
  ; CHECK-NEXT:   [[ADD1:%[0-9]+]]:_(s32) = G_ADD [[PHI1]], [[C1]]
  ; CHECK-NEXT:   [[ICMP1:%[0-9]+]]:_(s1) = G_ICMP intpred(eq), [[ADD1]](s32), [[C]]
  ; CHECK-NEXT:   G_BRCOND [[ICMP1]](s1), %bb.3
  ; CHECK-NEXT:   G_BR %bb.4
entry:
  %args = alloca ptr, align 4
  call void @llvm.va_start.p0(ptr nonnull %args)
  %empty = icmp eq i32 %count, 0
  br i1 %empty, label %for.cond.cleanup, label %for.body
for.cond.cleanup:
  %result = phi i32 [ 0, %entry ], [ %add, %for.body ]
  call void @llvm.va_end.p0(ptr nonnull %args)
  ret i32 %result
for.body:
  %sum = phi i32 [ %add, %for.body ], [ 0, %entry ]
  %i = phi i32 [ %inc, %for.body ], [ 0, %entry ]
  %tmp = va_arg ptr %args, i32
  %add = add i32 %tmp, %sum
  %inc = add i32 %i, 1
  %done = icmp eq i32 %inc, %count
  br i1 %done, label %for.cond.cleanup, label %for.body
}

; Calling our varargs method without extra args,
; all we need to do is pass 0 in r6
define i32 @call_va_empty() {
  ; CHECK-LABEL: name: call_va_empty
  ; CHECK: bb.1 (%ir-block.0):
  ; CHECK-NEXT:   [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 0
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 0, 0, implicit-def $r3, implicit $r3
  ; CHECK-NEXT:   $r6 = COPY [[C]](s32)
  ; CHECK-NEXT:   CALL @sum, csr, implicit-def $r31, implicit $r6, implicit-def $r10
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(s32) = COPY $r10
  ; CHECK-NEXT:   ADJCALLSTACKUP 0, 0, implicit-def $r3, implicit $r3
  ; CHECK-NEXT:   $r10 = COPY [[COPY]](s32)
  ; CHECK-NEXT:   RET implicit $r10
  %sum = call i32 (i32, ...) @sum(i32 0)
  ret i32 %sum
}

; All variadic arguments go on the stack,
; even if we have register space for them
define i32 @call_va_nonempty() {
  ; CHECK-LABEL: name: call_va_nonempty
  ; CHECK: bb.1 (%ir-block.0):
  ; CHECK-NEXT:   [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 3
  ; CHECK-NEXT:   [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 2
  ; CHECK-NEXT:   [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 4
  ; CHECK-NEXT:   [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 6
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 12, 0, implicit-def $r3, implicit $r3
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.2
  ; CHECK-NEXT:   G_STORE [[C1]](s32), [[FRAME_INDEX]](p0) :: (store (s32) into %fixed-stack.2)
  ; CHECK-NEXT:   [[FRAME_INDEX1:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.1
  ; CHECK-NEXT:   G_STORE [[C2]](s32), [[FRAME_INDEX1]](p0) :: (store (s32) into %fixed-stack.1)
  ; CHECK-NEXT:   [[FRAME_INDEX2:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.0
  ; CHECK-NEXT:   G_STORE [[C3]](s32), [[FRAME_INDEX2]](p0) :: (store (s32) into %fixed-stack.0)
  ; CHECK-NEXT:   $r6 = COPY [[C]](s32)
  ; CHECK-NEXT:   CALL @sum, csr, implicit-def $r31, implicit $r6, implicit-def $r10
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(s32) = COPY $r10
  ; CHECK-NEXT:   ADJCALLSTACKUP 12, 0, implicit-def $r3, implicit $r3
  ; CHECK-NEXT:   $r10 = COPY [[COPY]](s32)
  ; CHECK-NEXT:   RET implicit $r10
  %sum = call i32 (i32, ...) @sum(i32 3, i32 2, i32 4, i32 6)
  ret i32 %sum
}

; If we have two fixed arguments, they go in r6 and r7
declare void @va_2fixed(i32, i32, ...)
define void @call_va_2fixed() {
  ; CHECK-LABEL: name: call_va_2fixed
  ; CHECK: bb.1 (%ir-block.0):
  ; CHECK-NEXT:   [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 1
  ; CHECK-NEXT:   [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 2
  ; CHECK-NEXT:   [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 3
  ; CHECK-NEXT:   [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 4
  ; CHECK-NEXT:   [[C4:%[0-9]+]]:_(s32) = G_CONSTANT i32 5
  ; CHECK-NEXT:   [[C5:%[0-9]+]]:_(s32) = G_CONSTANT i32 6
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 16, 0, implicit-def $r3, implicit $r3
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.3
  ; CHECK-NEXT:   G_STORE [[C2]](s32), [[FRAME_INDEX]](p0) :: (store (s32) into %fixed-stack.3)
  ; CHECK-NEXT:   [[FRAME_INDEX1:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.2
  ; CHECK-NEXT:   G_STORE [[C3]](s32), [[FRAME_INDEX1]](p0) :: (store (s32) into %fixed-stack.2)
  ; CHECK-NEXT:   [[FRAME_INDEX2:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.1
  ; CHECK-NEXT:   G_STORE [[C4]](s32), [[FRAME_INDEX2]](p0) :: (store (s32) into %fixed-stack.1)
  ; CHECK-NEXT:   [[FRAME_INDEX3:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.0
  ; CHECK-NEXT:   G_STORE [[C5]](s32), [[FRAME_INDEX3]](p0) :: (store (s32) into %fixed-stack.0)
  ; CHECK-NEXT:   $r6 = COPY [[C]](s32)
  ; CHECK-NEXT:   $r7 = COPY [[C1]](s32)
  ; CHECK-NEXT:   CALL @va_2fixed, csr, implicit-def $r31, implicit $r6, implicit $r7
  ; CHECK-NEXT:   ADJCALLSTACKUP 16, 0, implicit-def $r3, implicit $r3
  ; CHECK-NEXT:   RET
  call void (i32, i32, ...) @va_2fixed(i32 1, i32 2, i32 3, i32 4, i32 5, i32 6)
  ret void
}

; If a variadic function has more than four fixed arguments,
; extra fixed arguments spill onto the stack, and varargs start after all of them.
; i.e. this function should return the value stored at r3+4
define i32 @va_5fixed(i32 %a, i32 %b, i32 %c, i32 %d, i32 %e, ...) {
  ; CHECK-LABEL: name: va_5fixed
  ; CHECK: bb.1 (%ir-block.0):
  ; CHECK-NEXT:   liveins: $r6, $r7, $r8, $r9
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(s32) = COPY $r6
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:_(s32) = COPY $r7
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:_(s32) = COPY $r8
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:_(s32) = COPY $r9
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.0
  ; CHECK-NEXT:   [[LOAD:%[0-9]+]]:_(s32) = G_LOAD [[FRAME_INDEX]](p0) :: (load (s32) from %fixed-stack.0)
  ; CHECK-NEXT:   [[FRAME_INDEX1:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.args
  ; CHECK-NEXT:   G_VASTART [[FRAME_INDEX1]](p0) :: (store (s32) into %ir.args)
  ; CHECK-NEXT:   [[VAARG:%[0-9]+]]:_(s32) = G_VAARG [[FRAME_INDEX1]](p0), 4
  ; CHECK-NEXT:   $r10 = COPY [[VAARG]](s32)
  ; CHECK-NEXT:   RET implicit $r10
  %args = alloca ptr, align 4
  call void @llvm.va_start.p0(ptr nonnull %args)
  %first = va_arg ptr %args, i32
  call void @llvm.va_end.p0(ptr nonnull %args)
  ret i32 %first
}

define i32 @call_va_5fixed() {
  ; CHECK-LABEL: name: call_va_5fixed
  ; CHECK: bb.1 (%ir-block.0):
  ; CHECK-NEXT:   [[C:%[0-9]+]]:_(s32) = G_CONSTANT i32 1
  ; CHECK-NEXT:   [[C1:%[0-9]+]]:_(s32) = G_CONSTANT i32 2
  ; CHECK-NEXT:   [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 3
  ; CHECK-NEXT:   [[C3:%[0-9]+]]:_(s32) = G_CONSTANT i32 4
  ; CHECK-NEXT:   [[C4:%[0-9]+]]:_(s32) = G_CONSTANT i32 5
  ; CHECK-NEXT:   [[C5:%[0-9]+]]:_(s32) = G_CONSTANT i32 6
  ; CHECK-NEXT:   ADJCALLSTACKDOWN 8, 0, implicit-def $r3, implicit $r3
  ; CHECK-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.1
  ; CHECK-NEXT:   G_STORE [[C4]](s32), [[FRAME_INDEX]](p0) :: (store (s32) into %fixed-stack.1)
  ; CHECK-NEXT:   [[FRAME_INDEX1:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.0
  ; CHECK-NEXT:   G_STORE [[C5]](s32), [[FRAME_INDEX1]](p0) :: (store (s32) into %fixed-stack.0)
  ; CHECK-NEXT:   $r6 = COPY [[C]](s32)
  ; CHECK-NEXT:   $r7 = COPY [[C1]](s32)
  ; CHECK-NEXT:   $r8 = COPY [[C2]](s32)
  ; CHECK-NEXT:   $r9 = COPY [[C3]](s32)
  ; CHECK-NEXT:   CALL @va_5fixed, csr, implicit-def $r31, implicit $r6, implicit $r7, implicit $r8, implicit $r9, implicit-def $r10
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:_(s32) = COPY $r10
  ; CHECK-NEXT:   ADJCALLSTACKUP 8, 0, implicit-def $r3, implicit $r3
  ; CHECK-NEXT:   $r10 = COPY [[COPY]](s32)
  ; CHECK-NEXT:   RET implicit $r10
  %result = call i32 (i32, i32, i32, i32, i32, ...) @va_5fixed(i32 1, i32 2, i32 3, i32 4, i32 5, i32 6)
  ret i32 %result
}
