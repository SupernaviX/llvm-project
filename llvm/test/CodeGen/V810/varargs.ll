; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 2
; RUN: llc < %s -march=v810 | FileCheck %s

; Basic variadic method just to confirm we're lowering the intrinsics at all
define i32 @sum(i32 %count, ...) {
; CHECK-LABEL: sum:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    add -4, r3
; CHECK-NEXT:    addi 4, r3, r7
; CHECK-NEXT:    cmp 0, r6
; CHECK-NEXT:    st.w r7, 0[r3]
; CHECK-NEXT:    be .LBB0_4
; CHECK-NEXT:  # %bb.1: # %for.body.preheader
; CHECK-NEXT:    mov 0, r7
; CHECK-NEXT:  .LBB0_2: # %for.body
; CHECK-NEXT:    # =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    ld.w 0[r3], r8
; CHECK-NEXT:    mov r8, r9
; CHECK-NEXT:    add 4, r9
; CHECK-NEXT:    st.w r9, 0[r3]
; CHECK-NEXT:    ld.w 0[r8], r10
; CHECK-NEXT:    add r7, r10
; CHECK-NEXT:    add -1, r6
; CHECK-NEXT:    mov r10, r7
; CHECK-NEXT:    bne .LBB0_2
; CHECK-NEXT:  # %bb.3: # %for.cond.cleanup
; CHECK-NEXT:    add 4, r3
; CHECK-NEXT:    jmp [r31]
; CHECK-NEXT:  .LBB0_4:
; CHECK-NEXT:    mov 0, r10
; CHECK-NEXT:    add 4, r3
; CHECK-NEXT:    jmp [r31]
entry:
  %args = alloca ptr, align 4
  call void @llvm.va_start.p0(ptr nonnull %args)
  %empty = icmp eq i32 %count, 0
  br i1 %empty, label %for.cond.cleanup, label %for.body
for.cond.cleanup:
  %result = phi i32 [ 0, %entry ], [ %add, %for.body ]
  call void @llvm.va_end.p0(ptr nonnull %args)
  ret i32 %result
for.body:
  %sum = phi i32 [ %add, %for.body ], [ 0, %entry ]
  %i = phi i32 [ %inc, %for.body ], [ 0, %entry ]
  %tmp = va_arg ptr %args, i32
  %add = add i32 %tmp, %sum
  %inc = add i32 %i, 1
  %done = icmp eq i32 %inc, %count
  br i1 %done, label %for.cond.cleanup, label %for.body
}

; Calling our varargs method without extra args,
; all we need to do is pass 0 in r6
define i32 @call_va_empty() {
; CHECK-LABEL: call_va_empty:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add -4, r3
; CHECK-NEXT:    mov 0, r6
; CHECK-NEXT:    st.w r31, 0[r3] # 4-byte Folded Spill
; CHECK-NEXT:    jal sum
; CHECK-NEXT:    ld.w 0[r3], r31 # 4-byte Folded Reload
; CHECK-NEXT:    add 4, r3
; CHECK-NEXT:    jmp [r31]
  %sum = call i32 (i32, ...) @sum(i32 0)
  ret i32 %sum
}

; All variadic arguments go on the stack,
; even if we have register space for them
define i32 @call_va_nonempty() {
; CHECK-LABEL: call_va_nonempty:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add -16, r3
; CHECK-NEXT:    mov 6, r6
; CHECK-NEXT:    st.w r31, 12[r3] # 4-byte Folded Spill
; CHECK-NEXT:    mov 2, r7
; CHECK-NEXT:    st.w r6, 8[r3]
; CHECK-NEXT:    mov 4, r6
; CHECK-NEXT:    st.w r6, 4[r3]
; CHECK-NEXT:    mov 3, r6
; CHECK-NEXT:    st.w r7, 0[r3]
; CHECK-NEXT:    jal sum
; CHECK-NEXT:    ld.w 12[r3], r31 # 4-byte Folded Reload
; CHECK-NEXT:    movea 16, r3, r3
; CHECK-NEXT:    jmp [r31]
  %sum = call i32 (i32, ...) @sum(i32 3, i32 2, i32 4, i32 6)
  ret i32 %sum
}

; If we have two fixed arguments, they go in r6 and r7
declare void @va_2fixed(i32, i32, ...)
define void @call_va_2fixed() {
; CHECK-LABEL: call_va_2fixed:
; CHECK:       # %bb.0:
; CHECK-NEXT:    movea -20, r3, r3
; CHECK-NEXT:    mov 6, r6
; CHECK-NEXT:    st.w r31, 16[r3] # 4-byte Folded Spill
; CHECK-NEXT:    mov 3, r8
; CHECK-NEXT:    mov 2, r7
; CHECK-NEXT:    st.w r6, 12[r3]
; CHECK-NEXT:    mov 5, r6
; CHECK-NEXT:    st.w r6, 8[r3]
; CHECK-NEXT:    mov 4, r6
; CHECK-NEXT:    st.w r6, 4[r3]
; CHECK-NEXT:    mov 1, r6
; CHECK-NEXT:    st.w r8, 0[r3]
; CHECK-NEXT:    jal va_2fixed
; CHECK-NEXT:    ld.w 16[r3], r31 # 4-byte Folded Reload
; CHECK-NEXT:    movea 20, r3, r3
; CHECK-NEXT:    jmp [r31]
  call void (i32, i32, ...) @va_2fixed(i32 1, i32 2, i32 3, i32 4, i32 5, i32 6)
  ret void
}

; If a variadic function has more than four fixed arguments,
; extra fixed arguments spill onto the stack, and varargs start after all of them.
; i.e. this function should return the value stored at r3+4
define i32 @va_5fixed(i32 %a, i32 %b, i32 %c, i32 %d, i32 %e, ...) {
; CHECK-LABEL: va_5fixed:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add -4, r3
; CHECK-NEXT:    addi 8, r3, r6
; CHECK-NEXT:    add 4, r6
; CHECK-NEXT:    st.w r6, 0[r3]
; CHECK-NEXT:    ld.w 8[r3], r10
; CHECK-NEXT:    add 4, r3
; CHECK-NEXT:    jmp [r31]
  %args = alloca ptr, align 4
  call void @llvm.va_start.p0(ptr nonnull %args)
  %first = va_arg ptr %args, i32
  call void @llvm.va_end.p0(ptr nonnull %args)
  ret i32 %first
}

define i32 @call_va_5fixed() {
; CHECK-LABEL: call_va_5fixed:
; CHECK:       # %bb.0:
; CHECK-NEXT:    add -12, r3
; CHECK-NEXT:    mov 6, r6
; CHECK-NEXT:    st.w r31, 8[r3] # 4-byte Folded Spill
; CHECK-NEXT:    mov 5, r10
; CHECK-NEXT:    mov 2, r7
; CHECK-NEXT:    mov 3, r8
; CHECK-NEXT:    mov 4, r9
; CHECK-NEXT:    st.w r6, 4[r3]
; CHECK-NEXT:    mov 1, r6
; CHECK-NEXT:    st.w r10, 0[r3]
; CHECK-NEXT:    jal va_5fixed
; CHECK-NEXT:    ld.w 8[r3], r31 # 4-byte Folded Reload
; CHECK-NEXT:    add 12, r3
; CHECK-NEXT:    jmp [r31]
  %result = call i32 (i32, i32, i32, i32, i32, ...) @va_5fixed(i32 1, i32 2, i32 3, i32 4, i32 5, i32 6)
  ret i32 %result
}
